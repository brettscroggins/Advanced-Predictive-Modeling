{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import timeit\n",
    "\n",
    "train=pd.read_csv(\"train_sales.csv\", header=0)\n",
    "test=pd.read_csv(\"test_sales.csv\", header=0)\n",
    "train=train[train['unit_sales']>=0]\n",
    "test=test[test['unit_sales']>=0]\n",
    "\n",
    "train=train[train['unit_sales']>0]\n",
    "test=test[test['unit_sales']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train['Unnamed: 0']\n",
    "del test['Unnamed: 0']\n",
    "train['full_date']=pd.to_datetime(train['full_date'])\n",
    "test['full_date']=pd.to_datetime(test['full_date'])\n",
    "train['day_of_week']=train['full_date'].dt.dayofweek\n",
    "test['day_of_week']=test['full_date'].dt.dayofweek\n",
    "def replace_nan(x):\n",
    "    if x!=True:\n",
    "        x=False\n",
    "    return x\n",
    "train['onpromotion']=train['onpromotion'].map(replace_nan)\n",
    "test['onpromotion']=test['onpromotion'].map(replace_nan)\n",
    "\n",
    "del train['full_date']\n",
    "del test['full_date']\n",
    "del train['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dum_dums_train=pd.get_dummies(train[['month', 'quarter', 'type', 'cluster', 'family', 'class', 'store_nbr', 'day_of_week']])\n",
    "train=pd.concat([train[['onpromotion', 'year', 'holiday', 'transactions', 'perishable', 'unit_sales', 'item_nbr']], dum_dums_train], axis=1)\n",
    "dum_dums_test=pd.get_dummies(test[['month', 'quarter', 'type', 'cluster', 'family', 'class', 'store_nbr', 'day_of_week']])\n",
    "test=pd.concat([test[['onpromotion', 'year', 'holiday', 'transactions', 'perishable', 'unit_sales', 'item_nbr']], dum_dums_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items in the test set that are not in the training set: [2116139, 2122947]\n",
      "there are 4014 items in both the training and validation set\n"
     ]
    }
   ],
   "source": [
    "test_items=test['item_nbr'].unique().tolist()\n",
    "train_items=train['item_nbr'].unique().tolist()\n",
    "\n",
    "test_only=list(set(test_items)-set(train_items))\n",
    "train_only=list(set(train_items)-set(test_items))\n",
    "\n",
    "predict=set(test_items) & set(train_items)\n",
    "\n",
    "print \"items in the test set that are not in the training set: {}\".format(test_only)\n",
    "print \"there are {} items in both the training and validation set\".format(len(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.554771178160252"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_val=train['unit_sales'].mean()\n",
    "\n",
    "avg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.554771178160252,\n",
       " 8.554771178160252,\n",
       " 8.554771178160252,\n",
       " 8.554771178160252,\n",
       " 8.554771178160252,\n",
       " 8.554771178160252]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*[avg_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (train_test_split,KFold)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brettscroggins/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/brettscroggins/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:357: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "201\n",
      "301\n",
      "401\n",
      "501\n",
      "601\n",
      "701\n",
      "801\n",
      "901\n",
      "1001\n",
      "1101\n",
      "1201\n",
      "1301\n",
      "1401\n",
      "1501\n",
      "1601\n",
      "1701\n",
      "1801\n",
      "1901\n",
      "2001\n",
      "2101\n",
      "2201\n",
      "2301\n",
      "2401\n",
      "2501\n",
      "2601\n",
      "2701\n",
      "2801\n",
      "2901\n",
      "3001\n",
      "3101\n",
      "3201\n",
      "3301\n",
      "3401\n",
      "3501\n",
      "3601\n",
      "3701\n",
      "3801\n",
      "3901\n",
      "4001\n",
      "1248.72709918\n"
     ]
    }
   ],
   "source": [
    "#line below for testing code\n",
    "\n",
    "train_save=train.copy(deep=True)\n",
    "test_save=test.copy(deep=True)\n",
    "\n",
    "mlp2 = MLPRegressor(hidden_layer_sizes=(2,), activation = 'tanh', learning_rate='adaptive', \n",
    "                    random_state=12, batch_size=200)\n",
    "\n",
    "perishable=[]\n",
    "unit_sales=[]\n",
    "unit_sales_pred=[]\n",
    "#item_nbr=[]\n",
    "\n",
    "n=0\n",
    "start=timeit.default_timer()\n",
    "\n",
    "for item in predict:\n",
    "    \n",
    "    n=n+1\n",
    "    \n",
    "    if n%100==1:\n",
    "        print n\n",
    "    \n",
    "    \n",
    "    train_sub=train_save[train_save['item_nbr']==item]\n",
    "    test_sub=test_save[test_save['item_nbr']==item]\n",
    "    y_test_sub=np.log(test_sub['unit_sales']+1)\n",
    "    y_train_sub=np.log(train_sub['unit_sales']+1)\n",
    "    del train_sub['unit_sales']\n",
    "    del test_sub['unit_sales']\n",
    "    \n",
    "    # Fitting on both X's and Y's\n",
    "    sub_mod = mlp2.fit(train_sub, y_train_sub)\n",
    "    sub_pred=sub_mod.predict(test_sub)\n",
    "    \n",
    "    perishable+=test_sub['perishable'].tolist()\n",
    "    unit_sales+=y_test_sub.tolist()\n",
    "    unit_sales_pred+=sub_pred.tolist()\n",
    "    \n",
    "\n",
    "elapsed=timeit.default_timer()-start\n",
    "\n",
    "print elapsed\n",
    "###don't forget the items that are only in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2514263 2514263 2514263\n"
     ]
    }
   ],
   "source": [
    "test_only=list(set(test_items)-set(train_items))\n",
    "\n",
    "for item in test_only:\n",
    "    \n",
    "    train_sub=train_save[train_save['item_nbr']==item]\n",
    "    test_sub=test_save[test_save['item_nbr']==item]\n",
    "    y_test_sub=np.log(test_sub['unit_sales']+1)\n",
    "    y_train_sub=np.log(train_sub['unit_sales']+1)\n",
    "    del train_sub['unit_sales']\n",
    "    del test_sub['unit_sales']\n",
    "    \n",
    "    #sub_pred=len(y_test_sub)*[avg_val]\n",
    "    perishable_list=len(y_test_sub)*[test_sub['perishable'].values[0]]\n",
    "    \n",
    "    perishable+=perishable_list\n",
    "    unit_sales+=y_test_sub.tolist()\n",
    "    unit_sales_pred+=len(y_test_sub)*[np.log(avg_val+1)]\n",
    "    \n",
    "print len(perishable), len(unit_sales), len(unit_sales_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78284487415326287"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=pd.DataFrame({'perishable': perishable, 'unit_sales': unit_sales, 'unit_sales_pred': unit_sales_pred})\n",
    "score['weight']=score['perishable']*0.25+1\n",
    "score['num']=score['weight']\n",
    "score['num']=score['num']*(score['unit_sales_pred']-score['unit_sales'])**2\n",
    "num=sum(score['num'])\n",
    "den=sum(score['weight'])\n",
    "nwrmsle=(float(num)/den)**0.5\n",
    "\n",
    "\n",
    "\n",
    "nwrmsle\n",
    "\n",
    "#len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
